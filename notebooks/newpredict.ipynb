{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "163faaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\3878505931.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[ordinal_features] = ordinal_encoder.fit_transform(X[ordinal_features])\n",
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\3878505931.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['city'] = X['city'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Read the diamonds_train.db file\n",
    "conn = sqlite3.connect('diamonds_train.db')\n",
    "\n",
    "# Fetch the required tables\n",
    "df_dim = pd.read_sql_query('SELECT * FROM diamonds_dimensions', conn)\n",
    "df_trans = pd.read_sql_query('SELECT * FROM diamonds_transactional', conn)\n",
    "df_prop = pd.read_sql_query('SELECT * FROM diamonds_properties', conn)\n",
    "df_cut = pd.read_sql_query('SELECT * FROM diamonds_cut', conn)\n",
    "df_color = pd.read_sql_query('SELECT * FROM diamonds_color', conn)\n",
    "df_clarity = pd.read_sql_query('SELECT * FROM diamonds_clarity', conn)\n",
    "df_city = pd.read_sql_query('SELECT * FROM diamonds_city', conn)\n",
    "\n",
    "# Merge the tables based on index_id\n",
    "df = pd.merge(df_dim, df_trans, on='index_id')\n",
    "df = pd.merge(df, df_prop, on='index_id')\n",
    "df = pd.merge(df, df_cut, on='cut_id')\n",
    "df = pd.merge(df, df_color, on='color_id')\n",
    "df = pd.merge(df, df_clarity, on='clarity_id')\n",
    "df = pd.merge(df, df_city, on='city_id')\n",
    "\n",
    "# Create X and y\n",
    "X = df[['carat', 'cut', 'color', 'clarity', 'x', 'y', 'z', 'depth', 'table', 'city']]\n",
    "y = df['price']\n",
    "\n",
    "# Convert non-numeric columns to numeric using OrdinalEncoder\n",
    "ordinal_features = ['cut', 'color', 'clarity', 'city']\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X[ordinal_features] = ordinal_encoder.fit_transform(X[ordinal_features])\n",
    "\n",
    "# Convert 'city' column to string type\n",
    "X['city'] = X['city'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "811f3e12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\1826366493.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numeric_features] = scaler.fit_transform(X[numeric_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 593.9563115316485\n"
     ]
    }
   ],
   "source": [
    "# Scale numerical features\n",
    "numeric_features = ['carat', 'x', 'y', 'z', 'depth', 'table']\n",
    "scaler = StandardScaler()\n",
    "X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline for preprocessing and modeling\n",
    "preprocessing = ColumnTransformer(\n",
    "    [('vectorizer', CountVectorizer(), 'city')],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression)),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'feature_selection__k': [5, 7, 10],\n",
    "    'regressor__n_estimators': [100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='neg_root_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "157dca8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3.67</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>J</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>4.18</td>\n",
       "      <td>Surat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.57</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>7.32</td>\n",
       "      <td>4.57</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.13</td>\n",
       "      <td>3.90</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.19</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13480</th>\n",
       "      <td>13480</td>\n",
       "      <td>0.57</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.35</td>\n",
       "      <td>5.32</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13481</th>\n",
       "      <td>13481</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.71</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.56</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13482</th>\n",
       "      <td>13482</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.53</td>\n",
       "      <td>Tel Aviv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13483</th>\n",
       "      <td>13483</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>58.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.85</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3.45</td>\n",
       "      <td>Surat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13484</th>\n",
       "      <td>13484</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.94</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13485 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  carat        cut color clarity  depth  table     x     y     z  \\\n",
       "0          0   0.79  Very Good     F     SI1   62.7   60.0  5.82  5.89  3.67   \n",
       "1          1   1.20      Ideal     J     VS1   61.0   57.0  6.81  6.89  4.18   \n",
       "2          2   1.57    Premium     H     SI1   62.2   61.0  7.38  7.32  4.57   \n",
       "3          3   0.90  Very Good     F     SI1   63.8   54.0  6.09  6.13  3.90   \n",
       "4          4   0.50  Very Good     F     VS1   62.9   58.0  5.05  5.09  3.19   \n",
       "...      ...    ...        ...   ...     ...    ...    ...   ...   ...   ...   \n",
       "13480  13480   0.57      Ideal     E     SI1   61.9   56.0  5.35  5.32  3.30   \n",
       "13481  13481   0.71      Ideal     I     VS2   62.2   55.0  5.71  5.73  3.56   \n",
       "13482  13482   0.70      Ideal     F     VS1   61.6   55.0  5.75  5.71  3.53   \n",
       "13483  13483   0.70  Very Good     F     SI2   58.8   57.0  5.85  5.89  3.45   \n",
       "13484  13484   0.40      Ideal     I    VVS2   62.4   55.0  4.70  4.73  2.94   \n",
       "\n",
       "                city  \n",
       "0          Amsterdam  \n",
       "1              Surat  \n",
       "2           Kimberly  \n",
       "3           Kimberly  \n",
       "4          Amsterdam  \n",
       "...              ...  \n",
       "13480      Amsterdam  \n",
       "13481  New York City  \n",
       "13482       Tel Aviv  \n",
       "13483          Surat  \n",
       "13484  New York City  \n",
       "\n",
       "[13485 rows x 11 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamantes_test = pd.read_csv('diamonds_test.csv')\n",
    "diamantes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d325aa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         0\n",
      "carat      0\n",
      "cut        0\n",
      "color      0\n",
      "clarity    0\n",
      "depth      0\n",
      "table      0\n",
      "x          0\n",
      "y          0\n",
      "z          0\n",
      "city       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the dataset\n",
    "print(diamantes_test.isnull().sum())\n",
    "\n",
    "# Drop rows with null values\n",
    "diamantes_test.dropna(inplace=True)\n",
    "\n",
    "# Remove commas and convert numeric columns to float\n",
    "numeric_cols = ['carat', 'x', 'y', 'z', 'depth', 'table']\n",
    "for col in numeric_cols:\n",
    "    diamantes_test[col] = diamantes_test[col].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "# Reorder the columns to match the order used during training\n",
    "columns_order = ['carat', 'cut', 'color', 'clarity', 'x', 'y', 'z', 'depth', 'table', 'city']\n",
    "diamantes_test = diamantes_test[columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e09f7377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\2158232106.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diamantes_test.loc[:, 'cut'] = encoder_cut.fit_transform(diamantes_test[['cut']])\n",
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\2158232106.py:11: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  diamantes_test.loc[:, 'cut'] = encoder_cut.fit_transform(diamantes_test[['cut']])\n",
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\2158232106.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diamantes_test.loc[:, 'color'] = encoder_color.fit_transform(diamantes_test[['color']])\n",
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\2158232106.py:12: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  diamantes_test.loc[:, 'color'] = encoder_color.fit_transform(diamantes_test[['color']])\n",
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\2158232106.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diamantes_test.loc[:, 'clarity'] = encoder_clarity.fit_transform(diamantes_test[['clarity']])\n",
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\2158232106.py:13: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  diamantes_test.loc[:, 'clarity'] = encoder_clarity.fit_transform(diamantes_test[['clarity']])\n",
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\2158232106.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diamantes_test.loc[:, 'city'] = encoder_city.fit_transform(diamantes_test[['city']])\n",
      "C:\\Users\\bfven\\AppData\\Local\\Temp\\ipykernel_14416\\2158232106.py:14: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  diamantes_test.loc[:, 'city'] = encoder_city.fit_transform(diamantes_test[['city']])\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Initialize the encoders\n",
    "encoder_cut = OrdinalEncoder()\n",
    "encoder_color = OrdinalEncoder()\n",
    "encoder_clarity = OrdinalEncoder()\n",
    "encoder_city = OrdinalEncoder()\n",
    "\n",
    "diamantes_test.loc[:, 'cut'] = encoder_cut.fit_transform(diamantes_test[['cut']])\n",
    "diamantes_test.loc[:, 'color'] = encoder_color.fit_transform(diamantes_test[['color']])\n",
    "diamantes_test.loc[:, 'clarity'] = encoder_clarity.fit_transform(diamantes_test[['clarity']])\n",
    "diamantes_test.loc[:, 'city'] = encoder_city.fit_transform(diamantes_test[['city']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e053cf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'color', 'clarity', 'x', 'y', 'z', 'depth', 'table',\n",
       "       'city'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamantes_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f6d54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamantes_test = diamantes_test[['carat', 'cut', 'color', 'clarity', 'x', 'y', 'z', 'depth', 'table','city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3fbab100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "diamantes_test[['carat', 'x', 'y', 'z', 'depth', 'table']] = scaler.fit_transform(diamantes_test[['carat', 'x', 'y', 'z', 'depth', 'table']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e6fbd2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'F'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m diamantes_test_encoded[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcarat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(diamantes_test_encoded[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcarat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m y_final \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(diamantes_test_encoded)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\m3_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:981\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    979\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    984\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\m3_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\m3_env\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\m3_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\m3_env\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\m3_env\\Lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'F'"
     ]
    }
   ],
   "source": [
    "# Perform one-hot encoding on the 'cut' column in the test dataset\n",
    "diamantes_test_encoded = pd.get_dummies(diamantes_test, columns=['cut'])\n",
    "\n",
    "# Ensure the columns in the test dataset match the columns used during training\n",
    "missing_cols = set(X_train.columns) - set(diamantes_test_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    diamantes_test_encoded[col] = 0\n",
    "\n",
    "# Reorder columns to match the training dataset\n",
    "diamantes_test_encoded = diamantes_test_encoded[X_train.columns]\n",
    "\n",
    "# Scale numerical features\n",
    "diamantes_test_encoded[['carat', 'x', 'y', 'z', 'depth', 'table']] = scaler.transform(diamantes_test_encoded[['carat', 'x', 'y', 'z', 'depth', 'table']])\n",
    "\n",
    "# Make predictions\n",
    "y_final = model.predict(diamantes_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a1c9fa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- cut_Fair\n- cut_Good\n- cut_Ideal\n- cut_Premium\n- cut_Very Good\nFeature names seen at fit time, yet now missing:\n- cut\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_final \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(diamantes_test)\n\u001b[0;32m      2\u001b[0m y_final\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\m3_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:981\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    979\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    984\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\m3_env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\m3_env\\Lib\\site-packages\\sklearn\\base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    490\u001b[0m ):\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \n\u001b[0;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m         )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\m3_env\\Lib\\site-packages\\sklearn\\base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    479\u001b[0m     )\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- cut_Fair\n- cut_Good\n- cut_Ideal\n- cut_Premium\n- cut_Very Good\nFeature names seen at fit time, yet now missing:\n- cut\n"
     ]
    }
   ],
   "source": [
    "y_final = model.predict(diamantes_test)\n",
    "y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee30e294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "044dd782",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submi_test02.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca790633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ce0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:m3_env]",
   "language": "python",
   "name": "conda-env-m3_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
